{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eknyqV5-oWpd"
      },
      "source": [
        "# Import libraries, load and transform data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kMFhFIuoWpf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:47:46.233594Z",
          "iopub.status.busy": "2023-09-24T05:47:46.233049Z",
          "iopub.status.idle": "2023-09-24T05:48:16.280452Z",
          "shell.execute_reply": "2023-09-24T05:48:16.279235Z",
          "shell.execute_reply.started": "2023-09-24T05:47:46.233557Z"
        },
        "id": "Zt7KzIzloWpf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Install necessary Python packages using pip\n",
        "\n",
        "# Use the 'pip' command to install packages\n",
        "# The '-q' flag stands for 'quiet,' which means it will suppress most output, making the installation process less verbose\n",
        "# We're installing the following packages:\n",
        "# - 'evaluate': This package is likely used for evaluation purposes, but the specific functionality is not clear from this line alone\n",
        "# - 'transformers': This package is commonly used for natural language processing tasks, such as working with pre-trained language models like BERT or GPT\n",
        "# - 'datasets': This package provides easy access to various datasets commonly used in machine learning and natural language processing tasks\n",
        "# - 'mlflow': MLflow is an open-source platform for managing the end-to-end machine learning lifecycle, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models\n",
        "\n",
        "# Note: Before running this code, make sure you have Python and pip installed on your system.\n",
        "# Also, ensure you have an internet connection since pip will download and install these packages from PyPI (Python Package Index).\n",
        "!pip install -U -q evaluate transformers datasets>=2.14.5 mlflow 2>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:48:44.719990Z",
          "iopub.status.busy": "2023-09-24T05:48:44.719614Z",
          "iopub.status.idle": "2023-09-24T05:48:59.375907Z",
          "shell.execute_reply": "2023-09-24T05:48:59.374932Z",
          "shell.execute_reply.started": "2023-09-24T05:48:44.719955Z"
        },
        "id": "hh7JMEvkoWpg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries and modules\n",
        "import warnings  # Import the 'warnings' module for handling warnings\n",
        "warnings.filterwarnings(\"ignore\")  # Ignore warnings during execution\n",
        "\n",
        "import gc  # Import 'gc' module for garbage collection\n",
        "import numpy as np  \n",
        "import pandas as pd  \n",
        "import itertools  # Import 'itertools' for iterators and looping\n",
        "from collections import Counter  # Import 'Counter' for counting elements\n",
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.metrics import (  \n",
        "    accuracy_score,  # For calculating accuracy\n",
        "    roc_auc_score,  # For ROC AUC score\n",
        "    confusion_matrix,  \n",
        "    classification_report,  \n",
        "    f1_score  \n",
        ")\n",
        "\n",
        "# Import custom modules and classes\n",
        "import evaluate\n",
        "from datasets import Dataset, Image, ClassLabel  # Import custom 'Dataset', 'ClassLabel', and 'Image' classes\n",
        "from transformers import (\n",
        "    TrainingArguments,\n",
        "    Trainer,  # For model training\n",
        "    ViTImageProcessor,  # For processing image data with ViT models\n",
        "    ViTForImageClassification,  # ViT model for image classification\n",
        "    DefaultDataCollator  # For collating data in the default way\n",
        ")\n",
        "import torch  # Import PyTorch for deep learning\n",
        "from torch.utils.data import DataLoader  # For creating data loaders\n",
        "from torchvision.transforms import (  # Import image transformation functions\n",
        "    CenterCrop,  # Center crop an image\n",
        "    Compose,  # Compose multiple image transformations\n",
        "    Normalize,  # Normalize image pixel values\n",
        "    RandomRotation,  # Apply random rotation to images\n",
        "    RandomResizedCrop,  # Crop and resize images randomly\n",
        "    RandomHorizontalFlip,  # Apply random horizontal flip\n",
        "    RandomAdjustSharpness,  # Adjust sharpness randomly\n",
        "    Resize,  # Resize images\n",
        "    ToTensor  # Convert images to PyTorch tensors\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:49:02.717357Z",
          "iopub.status.busy": "2023-09-24T05:49:02.716964Z",
          "iopub.status.idle": "2023-09-24T05:49:02.722338Z",
          "shell.execute_reply": "2023-09-24T05:49:02.721207Z",
          "shell.execute_reply.started": "2023-09-24T05:49:02.717326Z"
        },
        "id": "GtC31xBsoWph",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import the necessary module from the Python Imaging Library (PIL).\n",
        "from PIL import ImageFile\n",
        "\n",
        "# Enable the option to load truncated images.\n",
        "# This setting allows the PIL library to attempt loading images even if they are corrupted or incomplete.\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:49:14.031066Z",
          "iopub.status.busy": "2023-09-24T05:49:14.030675Z",
          "iopub.status.idle": "2023-09-24T05:49:22.735096Z",
          "shell.execute_reply": "2023-09-24T05:49:22.734263Z",
          "shell.execute_reply.started": "2023-09-24T05:49:14.031028Z"
        },
        "id": "5ESKvlTsoWph",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# use https://huggingface.co/docs/datasets/image_load for reference\n",
        "\n",
        "# Import necessary libraries\n",
        "image_dict = {}\n",
        "\n",
        "# Define the list of file names\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Initialize empty lists to store file names and labels\n",
        "file_names = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through all image files in the specified directory\n",
        "for file in sorted((Path('/kaggle/input/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/').glob('*/*/*.jpg'))):\n",
        "    # check number of such files in a directory\n",
        "    sample_dir = '/'.join(str(file).split('/')[:-1])+'/'\n",
        "    # num_files_in_dir = [len(x) for _, _, x in os.walk(sample_dir)][0]\n",
        "    file_names.append(str(file))  # Add the file path to the list\n",
        "    label = str(file).split('/')[-2]  # Extract the label from the file path\n",
        "    labels.append(label)  # Add the label to the list\n",
        "\n",
        "# Print the total number of file names and labels\n",
        "print(len(file_names), len(labels), len(set(labels)))\n",
        "\n",
        "# Create a dataset from the collected file names and labels\n",
        "# Converting the string path to Image() type so we are working with extensions\n",
        "dataset = Dataset.from_dict({\"image\": file_names, \"label\": labels}).cast_column(\"image\", Image())\n",
        "\n",
        "# Display the first image in the dataset\n",
        "dataset[0][\"image\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:49:22.745346Z",
          "iopub.status.busy": "2023-09-24T05:49:22.744939Z",
          "iopub.status.idle": "2023-09-24T05:49:22.756197Z",
          "shell.execute_reply": "2023-09-24T05:49:22.755126Z",
          "shell.execute_reply.started": "2023-09-24T05:49:22.745317Z"
        },
        "id": "n_vObzuZoWpi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a list of unique labels by converting 'labels' to a set and then back to a list\n",
        "labels_list = list(set(labels))\n",
        "\n",
        "# Initialize empty dictionaries to map labels to IDs and vice versa\n",
        "label2id, id2label = dict(), dict()\n",
        "\n",
        "# Iterate over the unique labels and assign each label an ID, and vice versa\n",
        "for i, label in enumerate(labels_list):\n",
        "    label2id[label] = i  # Map the label to its corresponding ID\n",
        "    id2label[i] = label  # Map the ID to its corresponding label\n",
        "\n",
        "# Print the resulting dictionaries for reference\n",
        "print(\"Mapping of IDs to Labels:\", id2label, '\\n')\n",
        "print(\"Mapping of Labels to IDs:\", label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:51:30.763772Z",
          "iopub.status.busy": "2023-09-24T05:51:30.762989Z",
          "iopub.status.idle": "2023-09-24T05:51:30.912358Z",
          "shell.execute_reply": "2023-09-24T05:51:30.911460Z",
          "shell.execute_reply.started": "2023-09-24T05:51:30.763738Z"
        },
        "id": "EL9IpMPxoWpi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating classlabels to match labels to IDs\n",
        "ClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n",
        "\n",
        "# Mapping labels to IDs\n",
        "def map_label2id(example):\n",
        "    example['label'] = ClassLabels.str2int(example['label'])\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(map_label2id, batched=True)\n",
        "\n",
        "# Casting label column to ClassLabel Object\n",
        "dataset = dataset.cast_column('label', ClassLabels)\n",
        "\n",
        "# Splitting the dataset into training and testing sets using an 80-20 split ratio.\n",
        "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, stratify_by_column=\"label\")\n",
        "\n",
        "# Extracting the training data from the split dataset.\n",
        "train_data = dataset['train']\n",
        "\n",
        "# Extracting the testing data from the split dataset.\n",
        "test_data = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:51:33.606684Z",
          "iopub.status.busy": "2023-09-24T05:51:33.606003Z",
          "iopub.status.idle": "2023-09-24T05:51:34.099324Z",
          "shell.execute_reply": "2023-09-24T05:51:34.098410Z",
          "shell.execute_reply.started": "2023-09-24T05:51:33.606652Z"
        },
        "id": "m2BvUP7ioWpi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the pre-trained ViT model string\n",
        "model_str = 'google/vit-base-patch16-224-in21k'\n",
        "\n",
        "# Create a processor for ViT model input from the pre-trained model\n",
        "processor = ViTImageProcessor.from_pretrained(model_str)\n",
        "\n",
        "# Retrieve the image mean and standard deviation used for normalization\n",
        "image_mean, image_std = processor.image_mean, processor.image_std\n",
        "\n",
        "# Get the size (height) of the ViT model's input images\n",
        "size = processor.size[\"height\"]\n",
        "print(\"Size: \", size)\n",
        "\n",
        "# Define a normalization transformation for the input images\n",
        "normalize = Normalize(mean=image_mean, std=image_std)\n",
        "\n",
        "# Define a set of transformations for training data\n",
        "_train_transforms = Compose(\n",
        "    [\n",
        "        Resize((size, size)),             # Resize images to the ViT model's input size\n",
        "        RandomRotation(30),               # Apply random rotation up to 30 degrees\n",
        "        RandomAdjustSharpness(2),         # Adjust sharpness randomly\n",
        "        ToTensor(),                       # Convert images to tensors\n",
        "        normalize                         # Normalize images using mean and std\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define a set of transformations for validation data\n",
        "_val_transforms = Compose(\n",
        "    [\n",
        "        Resize((size, size)),             # Resize images to the ViT model's input size\n",
        "        ToTensor(),                       # Convert images to tensors\n",
        "        normalize                         # Normalize images using mean and std\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define a function to apply training transformations to a batch of examples\n",
        "def train_transforms(examples):\n",
        "    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
        "    return examples\n",
        "\n",
        "# Define a function to apply validation transformations to a batch of examples\n",
        "def val_transforms(examples):\n",
        "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:51:35.352311Z",
          "iopub.status.busy": "2023-09-24T05:51:35.350070Z",
          "iopub.status.idle": "2023-09-24T05:51:35.369177Z",
          "shell.execute_reply": "2023-09-24T05:51:35.368155Z",
          "shell.execute_reply.started": "2023-09-24T05:51:35.352267Z"
        },
        "id": "NUVlZ0QaoWpj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set the transforms for the training data\n",
        "train_data.set_transform(train_transforms)\n",
        "\n",
        "# Set the transforms for the test/validation data\n",
        "test_data.set_transform(val_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:51:36.758758Z",
          "iopub.status.busy": "2023-09-24T05:51:36.758414Z",
          "iopub.status.idle": "2023-09-24T05:51:36.764255Z",
          "shell.execute_reply": "2023-09-24T05:51:36.763337Z",
          "shell.execute_reply.started": "2023-09-24T05:51:36.758731Z"
        },
        "id": "uinqmhN6oWpj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a collate function that prepares batched data for model training.\n",
        "def collate_fn(examples):\n",
        "    # Stack the pixel values from individual examples into a single tensor.\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "\n",
        "    # Convert the label strings in examples to corresponding numeric IDs using label2id dictionary.\n",
        "    labels = torch.tensor([example['label'] for example in examples])\n",
        "\n",
        "    # Return a dictionary containing the batched pixel values and labels.\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZJexwHPoWpj"
      },
      "source": [
        "# Load, train, and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:51:39.730480Z",
          "iopub.status.busy": "2023-09-24T05:51:39.729351Z",
          "iopub.status.idle": "2023-09-24T05:51:52.300400Z",
          "shell.execute_reply": "2023-09-24T05:51:52.299360Z",
          "shell.execute_reply.started": "2023-09-24T05:51:39.730443Z"
        },
        "id": "KlU3UFl-oWpj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a ViTForImageClassification model from a pretrained checkpoint with a specified number of output labels.\n",
        "model = ViTForImageClassification.from_pretrained(model_str, num_labels=len(labels_list))\n",
        "\n",
        "# Configure the mapping of class labels to their corresponding indices for later reference.\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "\n",
        "# Calculate and print the number of trainable parameters in millions for the model.\n",
        "print(model.num_parameters(only_trainable=True) / 1e6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:51:52.302796Z",
          "iopub.status.busy": "2023-09-24T05:51:52.302366Z",
          "iopub.status.idle": "2023-09-24T05:51:53.671914Z",
          "shell.execute_reply": "2023-09-24T05:51:53.670968Z",
          "shell.execute_reply.started": "2023-09-24T05:51:52.302762Z"
        },
        "id": "2-B7VnREoWpj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the accuracy metric from a module named 'evaluate'\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define a function 'compute_metrics' to calculate evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    # Extract model predictions from the evaluation prediction object\n",
        "    predictions = eval_pred.predictions\n",
        "\n",
        "    # Extract true labels from the evaluation prediction object\n",
        "    label_ids = eval_pred.label_ids\n",
        "\n",
        "    # Calculate accuracy using the loaded accuracy metric\n",
        "    # Convert model predictions to class labels by selecting the class with the highest probability (argmax)\n",
        "    predicted_labels = predictions.argmax(axis=1)\n",
        "\n",
        "    # Calculate accuracy score by comparing predicted labels to true labels\n",
        "    acc_score = accuracy.compute(predictions=predicted_labels, references=label_ids)['accuracy']\n",
        "\n",
        "    # Return the computed accuracy as a dictionary with the key \"accuracy\"\n",
        "    return {\n",
        "        \"accuracy\": acc_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:51:57.573655Z",
          "iopub.status.busy": "2023-09-24T05:51:57.572968Z",
          "iopub.status.idle": "2023-09-24T05:51:57.581575Z",
          "shell.execute_reply": "2023-09-24T05:51:57.580443Z",
          "shell.execute_reply.started": "2023-09-24T05:51:57.573623Z"
        },
        "id": "wBL3n6ZmoWpj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the name of the evaluation metric to be used during training and evaluation.\n",
        "metric_name = \"accuracy\"\n",
        "\n",
        "# Define the name of the model, which will be used to create a directory for saving model checkpoints and outputs.\n",
        "model_name = \"medicinal_plants_image_detection\"\n",
        "\n",
        "# Define the number of training epochs for the model.\n",
        "num_train_epochs = 30\n",
        "\n",
        "# Create an instance of TrainingArguments to configure training settings.\n",
        "args = TrainingArguments(\n",
        "    # Specify the directory where model checkpoints and outputs will be saved.\n",
        "    output_dir=model_name,\n",
        "\n",
        "    # Specify the directory where training logs will be stored.\n",
        "    logging_dir='./logs',\n",
        "\n",
        "    # Define the evaluation strategy, which is performed at the end of each epoch.\n",
        "    evaluation_strategy=\"epoch\",\n",
        "\n",
        "    # Set the learning rate for the optimizer.\n",
        "    learning_rate=1e-5,\n",
        "\n",
        "    # Define the batch size for training on each device.\n",
        "    per_device_train_batch_size=32,\n",
        "\n",
        "    # Define the batch size for evaluation on each device.\n",
        "    per_device_eval_batch_size=8,\n",
        "\n",
        "    # Specify the total number of training epochs.\n",
        "    num_train_epochs=num_train_epochs,\n",
        "\n",
        "    # Apply weight decay to prevent overfitting.\n",
        "    weight_decay=0.02,\n",
        "\n",
        "    # Set the number of warm-up steps for the learning rate scheduler.\n",
        "    warmup_steps=50,\n",
        "\n",
        "    # Disable the removal of unused columns from the dataset.\n",
        "    remove_unused_columns=False,\n",
        "\n",
        "    # Define the strategy for saving model checkpoints (per epoch in this case).\n",
        "    save_strategy='epoch',\n",
        "\n",
        "    # Load the best model at the end of training.\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        "    # Limit the total number of saved checkpoints to save space.\n",
        "    save_total_limit=1,\n",
        "\n",
        "    # Specify that training progress should be reported to MLflow.\n",
        "    report_to=\"mlflow\"  # log to mlflow\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:52:09.140946Z",
          "iopub.status.busy": "2023-09-24T05:52:09.140419Z",
          "iopub.status.idle": "2023-09-24T05:52:13.928118Z",
          "shell.execute_reply": "2023-09-24T05:52:13.927062Z",
          "shell.execute_reply.started": "2023-09-24T05:52:09.140906Z"
        },
        "id": "3B97x0PsoWpk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a Trainer instance for fine-tuning a language model.\n",
        "\n",
        "# - `model`: The pre-trained language model to be fine-tuned.\n",
        "# - `args`: Configuration settings and hyperparameters for training.\n",
        "# - `train_dataset`: The dataset used for training the model.\n",
        "# - `eval_dataset`: The dataset used for evaluating the model during training.\n",
        "# - `data_collator`: A function that defines how data batches are collated and processed.\n",
        "# - `compute_metrics`: A function for computing custom evaluation metrics.\n",
        "# - `tokenizer`: The tokenizer used for processing text data.\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:52:19.890422Z",
          "iopub.status.busy": "2023-09-24T05:52:19.889925Z",
          "iopub.status.idle": "2023-09-24T05:54:25.238137Z",
          "shell.execute_reply": "2023-09-24T05:54:25.237047Z",
          "shell.execute_reply.started": "2023-09-24T05:52:19.890387Z"
        },
        "id": "-WRVCnj7oWpk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Evaluate the pre-training model's performance on a test dataset.\n",
        "# This function calculates various metrics such as accuracy, loss, etc.,\n",
        "# to assess how well the model is performing on unseen data.\n",
        "\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T05:54:25.240401Z",
          "iopub.status.busy": "2023-09-24T05:54:25.239962Z",
          "iopub.status.idle": "2023-09-24T11:21:26.123058Z",
          "shell.execute_reply": "2023-09-24T11:21:26.122083Z",
          "shell.execute_reply.started": "2023-09-24T05:54:25.240368Z"
        },
        "id": "qitQRfYBoWpk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Start training the model using the trainer object.\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:21:48.119524Z",
          "iopub.status.busy": "2023-09-24T11:21:48.119177Z",
          "iopub.status.idle": "2023-09-24T11:23:22.943502Z",
          "shell.execute_reply": "2023-09-24T11:23:22.942462Z",
          "shell.execute_reply.started": "2023-09-24T11:21:48.119496Z"
        },
        "id": "84St5pLfoWpk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Evaluate the post-training model's performance on the validation or test dataset.\n",
        "# This function computes various evaluation metrics like accuracy, loss, etc.\n",
        "# and provides insights into how well the model is performing.\n",
        "\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:27:36.900118Z",
          "iopub.status.busy": "2023-09-24T11:27:36.899722Z",
          "iopub.status.idle": "2023-09-24T11:29:11.659006Z",
          "shell.execute_reply": "2023-09-24T11:29:11.657931Z",
          "shell.execute_reply.started": "2023-09-24T11:27:36.900089Z"
        },
        "id": "KXK18OF6oWpk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Use the trained 'trainer' to make predictions on the 'test_data'.\n",
        "outputs = trainer.predict(test_data)\n",
        "\n",
        "# Print the metrics obtained from the prediction outputs.\n",
        "print(outputs.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:29:11.661604Z",
          "iopub.status.busy": "2023-09-24T11:29:11.661050Z",
          "iopub.status.idle": "2023-09-24T11:29:30.943778Z",
          "shell.execute_reply": "2023-09-24T11:29:30.942684Z",
          "shell.execute_reply.started": "2023-09-24T11:29:11.661570Z"
        },
        "id": "V8J3Ve_3oWpk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Extract the true labels from the model outputs\n",
        "y_true = outputs.label_ids\n",
        "\n",
        "# Predict the labels by selecting the class with the highest probability\n",
        "y_pred = outputs.predictions.argmax(1)\n",
        "\n",
        "# Define a function to plot a confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):\n",
        "    \"\"\"\n",
        "    This function plots a confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "        cm (array-like): Confusion matrix as returned by sklearn.metrics.confusion_matrix.\n",
        "        classes (list): List of class names, e.g., ['Class 0', 'Class 1'].\n",
        "        title (str): Title for the plot.\n",
        "        cmap (matplotlib colormap): Colormap for the plot.\n",
        "    \"\"\"\n",
        "    # Create a figure with a specified size\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Display the confusion matrix as an image with a colormap\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    # Define tick marks and labels for the classes on the axes\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.0f'\n",
        "    # Add text annotations to the plot indicating the values in the cells\n",
        "    thresh = cm.max() / 2.0\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    # Label the axes\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    # Ensure the plot layout is tight\n",
        "    plt.tight_layout()\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Display accuracy and F1 score\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Get the confusion matrix if there are a small number of labels\n",
        "if len(labels_list) <= 100:\n",
        "    # Compute the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Plot the confusion matrix using the defined function\n",
        "    plot_confusion_matrix(cm, labels_list, figsize=(18, 16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:29:30.945790Z",
          "iopub.status.busy": "2023-09-24T11:29:30.945442Z",
          "iopub.status.idle": "2023-09-24T11:29:31.475580Z",
          "shell.execute_reply": "2023-09-24T11:29:31.474553Z",
          "shell.execute_reply.started": "2023-09-24T11:29:30.945758Z"
        },
        "id": "BKRKBmkMoWpk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Save the trained model: This line of code is responsible for saving the model\n",
        "# that has been trained using the trainer object. It will serialize the model\n",
        "# and its associated weights, making it possible to reload and use the model\n",
        "# in the future without the need to retrain it.\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SDQF_0koWpk",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:31:01.136554Z",
          "iopub.status.busy": "2023-09-24T11:31:01.136192Z",
          "iopub.status.idle": "2023-09-24T11:31:02.282883Z",
          "shell.execute_reply": "2023-09-24T11:31:02.281899Z",
          "shell.execute_reply.started": "2023-09-24T11:31:01.136525Z"
        },
        "id": "Zvtn3pPzoWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import the 'pipeline' function from the 'transformers' library.\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create a pipeline for image classification tasks.\n",
        "# You need to specify the 'model_name' and the 'device' to use for inference.\n",
        "# - 'model_name': The name of the pre-trained model to be used for image classification.\n",
        "# - 'device': Specifies the device to use for running the model (0 for GPU, -1 for CPU).\n",
        "pipe = pipeline('image-classification', model=model_name, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:31:02.285207Z",
          "iopub.status.busy": "2023-09-24T11:31:02.284849Z",
          "iopub.status.idle": "2023-09-24T11:31:02.425996Z",
          "shell.execute_reply": "2023-09-24T11:31:02.425073Z",
          "shell.execute_reply.started": "2023-09-24T11:31:02.285175Z"
        },
        "id": "kiB9_IXtoWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Accessing an image from the 'test_data' dataset using index 1.\n",
        "image = test_data[1][\"image\"]\n",
        "\n",
        "# Displaying the 'image' variable.\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:31:03.524396Z",
          "iopub.status.busy": "2023-09-24T11:31:03.523997Z",
          "iopub.status.idle": "2023-09-24T11:31:03.573627Z",
          "shell.execute_reply": "2023-09-24T11:31:03.572587Z",
          "shell.execute_reply.started": "2023-09-24T11:31:03.524365Z"
        },
        "id": "0jWu2CwQoWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Apply the 'pipe' function to process the 'image' variable.\n",
        "pipe(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:31:04.274999Z",
          "iopub.status.busy": "2023-09-24T11:31:04.274650Z",
          "iopub.status.idle": "2023-09-24T11:31:04.289627Z",
          "shell.execute_reply": "2023-09-24T11:31:04.288597Z",
          "shell.execute_reply.started": "2023-09-24T11:31:04.274970Z"
        },
        "id": "VCJyKwdvoWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This line of code accesses the \"label\" attribute of a specific element in the test_data list.\n",
        "# It's used to retrieve the actual label associated with a test data point.\n",
        "id2label[test_data[1][\"label\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPZBlj_7oWpl"
      },
      "source": [
        "# Send model to Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T22:54:57.008223Z",
          "iopub.status.busy": "2023-09-23T22:54:57.007215Z",
          "iopub.status.idle": "2023-09-23T22:55:09.002738Z",
          "shell.execute_reply": "2023-09-23T22:55:09.001434Z",
          "shell.execute_reply.started": "2023-09-23T22:54:57.008179Z"
        },
        "id": "mzzhn3wBoWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:31:08.989869Z",
          "iopub.status.busy": "2023-09-24T11:31:08.989514Z",
          "iopub.status.idle": "2023-09-24T11:31:09.025530Z",
          "shell.execute_reply": "2023-09-24T11:31:09.024609Z",
          "shell.execute_reply.started": "2023-09-24T11:31:08.989840Z"
        },
        "id": "I6ow-Sq9oWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import the necessary module to interact with the Hugging Face Hub.\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Perform a login to the Hugging Face Hub.\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-23T22:55:16.450707Z",
          "iopub.status.busy": "2023-09-23T22:55:16.450331Z",
          "iopub.status.idle": "2023-09-23T22:55:30.548413Z",
          "shell.execute_reply": "2023-09-23T22:55:30.547126Z",
          "shell.execute_reply.started": "2023-09-23T22:55:16.450676Z"
        },
        "id": "mLfppMwwoWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install huggingface-hub==0.14.1\n",
        "!huggingface-cli login --token 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:31:18.108993Z",
          "iopub.status.busy": "2023-09-24T11:31:18.108632Z",
          "iopub.status.idle": "2023-09-24T11:31:18.505843Z",
          "shell.execute_reply": "2023-09-24T11:31:18.504836Z",
          "shell.execute_reply.started": "2023-09-24T11:31:18.108963Z"
        },
        "id": "1lFB2QAooWpl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import the HfApi class from the huggingface_hub library.\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Create an instance of the HfApi class.\n",
        "api = HfApi()\n",
        "\n",
        "# Define the repository ID by combining the username \"dima806\" with the model name.\n",
        "repo_id = f\"JanR317/{model_name}\"\n",
        "try:\n",
        "    # Attempt to create a new repository on the Hugging Face Model Hub using the specified repo_id.\n",
        "    api.create_repo(repo_id)\n",
        "    # If the repository creation is successful, print a message indicating that the repository was created.\n",
        "    print(f\"Repo {repo_id} created\")\n",
        "except:\n",
        "    # If an exception is raised, print a message indicating that the repository already exists.\n",
        "    print(f\"Repo {repo_id} already exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-09-24T11:31:22.160812Z",
          "iopub.status.busy": "2023-09-24T11:31:22.160399Z",
          "iopub.status.idle": "2023-09-24T11:32:40.660528Z",
          "shell.execute_reply": "2023-09-24T11:32:40.659188Z",
          "shell.execute_reply.started": "2023-09-24T11:31:22.160783Z"
        },
        "id": "dkzbEmt-oWpm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Uploading a folder to the Hugging Face Model Hub\n",
        "api.upload_folder(\n",
        "    folder_path=model_name,  # The path to the folder to be uploaded\n",
        "    path_in_repo=\".\",  # The path where the folder will be stored in the repository\n",
        "    repo_id=repo_id,  # The ID of the repository where the folder will be uploaded\n",
        "    repo_type=\"model\"  # The type of the repository (in this case, a model repository)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F6H7veMoWpn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NutV9ok-oWpn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
