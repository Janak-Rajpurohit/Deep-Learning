{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When data is huge, the RAM can;t take too much load \n",
    "<br>it divides the  the data into batches and loads the batches .\n",
    "* from **tf.data.Dataset.list_files(images)** to load data.\n",
    "* **tf.data.filter** to filter  before loading batch.\n",
    "* **tf.data.map** to apply function(converting img to numoy arr ,<br>rescalling) on every element(intensities) of array. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sales = [21,22,-108,31,-1,32,34,31]\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)  -  21\n",
      "tf.Tensor(22, shape=(), dtype=int32)  -  22\n",
      "tf.Tensor(-108, shape=(), dtype=int32)  -  -108\n",
      "tf.Tensor(31, shape=(), dtype=int32)  -  31\n",
      "tf.Tensor(-1, shape=(), dtype=int32)  -  -1\n",
      "tf.Tensor(32, shape=(), dtype=int32)  -  32\n",
      "tf.Tensor(34, shape=(), dtype=int32)  -  34\n",
      "tf.Tensor(31, shape=(), dtype=int32)  -  31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:\n",
    "    print(sales,\" - \",sales.numpy())            #individual element is tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)  -  21\n",
      "tf.Tensor(22, shape=(), dtype=int32)  -  22\n",
      "tf.Tensor(-108, shape=(), dtype=int32)  -  -108\n"
     ]
    }
   ],
   "source": [
    "# tking sfirst 3 elements \n",
    "for sales in tf_dataset.take(3):\n",
    "    print(sales,\" - \",sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = tf_dataset.filter(lambda x:x>0)   # remove nagative value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in filtered_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "220\n",
      "-1080\n",
      "310\n",
      "-10\n",
      "320\n",
      "340\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "# multiplying every ele by 10\n",
    "tf_dataset = tf_dataset.map(lambda x: x*10)\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "220\n",
      "-10\n",
      "-1080\n",
      "320\n",
      "310\n",
      "340\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "# shuffling the data\n",
    "#  it makes a buffer of given size then pick random val from that and so on\n",
    "tf_dataset = tf_dataset.shuffle(buffer_size = 2)\n",
    "for sales in tf_dataset.as_numpy_iterator():    # it will iterator elem as numpy array\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  220 -1080   210   340]\n",
      "[310 -10 310 320]\n"
     ]
    }
   ],
   "source": [
    "# making batch\n",
    "for sales in tf_dataset.batch(4):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset.list_files('plant_seedling/*/*/*/*/*')  #reading all folders indside image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
